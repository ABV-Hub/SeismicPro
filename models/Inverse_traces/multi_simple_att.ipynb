{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "from seismicpro.batchflow import Pipeline, Dataset, B, V, D\n",
    "from seismicpro.batchflow.models.torch import ResNet18, VGG7\n",
    "from seismicpro.src import TraceIndex, SeismicDataset, FieldIndex, KNNIndex\n",
    "from seismicpro.src.seismic_batch import (SeismicBatch,\n",
    "                                            seismic_plot)\n",
    "from seismicpro.batchflow.models.torch.layers import ConvBlock\n",
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seismicpro.batchflow import action, inbatch_parallel\n",
    "\n",
    "class InverseBatch_2d(SeismicBatch):\n",
    "    @action\n",
    "    @inbatch_parallel(init='_init_component')\n",
    "    def inv_traces(self, index, src, dst, p=.5):\n",
    "        pos = self.get_pos(None, src, index)\n",
    "        traces = getattr(self, src)[pos]\n",
    "        size = traces.shape[0]# * traces.shape[0]\n",
    "        mask = np.random.choice([1, -1], size=size, p=(1-p, p))\n",
    "        getattr(self, dst[0])[pos] = traces * mask.reshape(-1, 1)\n",
    "        getattr(self, dst[1])[pos] = 1 - np.clip(mask, 0, 1)\n",
    "\n",
    "    @action\n",
    "    def update_batch(self, src, from_cont):\n",
    "        batch = getattr(self, src[0])\n",
    "        labels = getattr(self, src[1])\n",
    "        if from_cont[0] is None:\n",
    "            return self\n",
    "        new_data = from_cont[0][0]\n",
    "        new_labels = from_cont[0][1]\n",
    "        batch = np.vstack((batch, new_data))\n",
    "        labels = np.vstack((labels, new_labels))\n",
    "        setattr(self, src[0], batch)\n",
    "        setattr(self, src[1], labels)\n",
    "        return self\n",
    "\n",
    "    @action\n",
    "    def HNS(self, src, labels, preds, metric, to, n_worse=50):\n",
    "        order = metric(labels, preds)\n",
    "        sigm = torch.nn.Sigmoid()\n",
    "        preds = sigm(torch.Tensor(preds))\n",
    "        to[0] = [getattr(self, src)[order[:n_worse]], labels[order[:n_worse]], preds[order[:n_worse]]]\n",
    "        return self\n",
    "\n",
    "def draw_res(loss, val_score, test_score, title):\n",
    "    _, ax = plt.subplots(1, 2, figsize=(20, 9))\n",
    "    ax[0].plot(loss[-300:], label='Loss')\n",
    "    ax[1].plot(val_score, label='Val F1')\n",
    "    ax[1].plot(test_score, label='Test F1')\n",
    "    ax[0].set_title(title)\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    ax[0].grid()\n",
    "    ax[1].grid()\n",
    "    plt.show()\n",
    "    \n",
    "def create_test_ppl(train_ppl, data, mode='w'):\n",
    "    test_ppl = (Pipeline().load(components='raw', fmt='segy')\n",
    "              .standardize(src='raw', dst='raw')\n",
    "              .inv_traces(src='raw', dst=['raw', 'labels'], p=0.0026)\n",
    "              .import_model('model', train_ppl, 'model')\n",
    "              .preprocess_component(src='raw', dst='raw')\n",
    "              .preprocess_answers(src='labels', dst='labels')\n",
    "              .init_variable('pred', init_on_each_run=list())\n",
    "              .init_variable('labels', init_on_each_run=list())\n",
    "              .update_variable('labels', B('labels'), mode=mode) \n",
    "              .predict_model('model', B('raw'), fetches='predictions',\n",
    "                             save_to=V('pred', mode=mode))) << data\n",
    "    return test_ppl\n",
    "\n",
    "def get_results(ppl):\n",
    "    sigm = torch.nn.Sigmoid()\n",
    "    pred = sigm(torch.Tensor(ppl.v('pred')))\n",
    "    preds = np.array(np.array(pred) > .5, dtype=int).ravel()\n",
    "    labels = np.array(ppl.v('labels')).ravel()\n",
    "    return preds, labels\n",
    "\n",
    "def create_test_ppl(train_ppl, data, mode='w'):\n",
    "    test_ppl = (Pipeline().load(components='raw', fmt='segy')\n",
    "              .standardize(src='raw', dst='raw')\n",
    "              .inv_traces(src='raw', dst=['raw', 'labels'], p=0.0026)\n",
    "              .import_model('model', train_ppl, 'model')\n",
    "              .apply_transform_all(src='raw', dst='raw', func=lambda x: np.expand_dims(np.stack(x), axis=1).astype(np.float32))\n",
    "              .apply_transform_all(src='labels', dst='labels', func=lambda x: np.stack(x).astype(np.float32))\n",
    "              .init_variable('pred', init_on_each_run=list())\n",
    "              .init_variable('labels', init_on_each_run=list())\n",
    "              .update_variable('labels', B('labels'), mode=mode) \n",
    "              .predict_model('model', B('raw'), fetches='predictions',\n",
    "                             save_to=V('pred', mode=mode))) << data\n",
    "    return test_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEIGH = 2\n",
    "pal_path = '/data/FB/dataset_1/Pal_Flatiron_1k.sgy'\n",
    "wz_path = '/data/FB/dataset_2/WZ_Flatiron_1k.sgy'\n",
    "\n",
    "pal_index = KNNIndex(name='raw', path=pal_path, extra_headers=['offset'], n_neighbors=N_NEIGH)\n",
    "pal_index = pal_index.create_subset(pal_index.indices[:100000])\n",
    "pal_index.split()\n",
    "pal_data_tr = Dataset(pal_index.train, InverseBatch_2d)\n",
    "pal_data_te = Dataset(pal_index.test, InverseBatch_2d)\n",
    "\n",
    "wz_index = KNNIndex(name='raw', path=wz_path, extra_headers=['offset'], n_neighbors=N_NEIGH)\n",
    "wz_index = wz_index.create_subset(wz_index.indices[:100000])\n",
    "wz_index.split()\n",
    "wz_data_tr = Dataset(wz_index.train, InverseBatch_2d)\n",
    "wz_data_te = Dataset(wz_index.test, InverseBatch_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seismicpro.batchflow import L, I\n",
    "prep_ppl = (Pipeline()\n",
    "          .load(components='raw', fmt='segy')\n",
    "          .standardize(src='raw', dst='raw')\n",
    "          .init_variable('prob', init_on_each_run=float)\n",
    "          .update_variable('prob', L(lambda x, m: m/(2*m + x**(1.4)))(I(), I('maximum')), mode='w')\n",
    "          .inv_traces(src='raw', dst=['raw', 'labels'], p=V('prob'))\n",
    "          .apply_transform_all(src='raw', dst='raw', func=lambda x: np.expand_dims(np.stack(x), axis=1).astype(np.float32))\n",
    "          .apply_transform_all(src='labels', dst='labels', func=lambda x: np.stack(x).astype(np.float32))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 751\n",
    "inputs_config = {\n",
    "    'raw': {'shape': (1, N_NEIGH, SIZE)}, \n",
    "    'masks': {'shape': (N_NEIGH, )}\n",
    "    }\n",
    "\n",
    "config = {\n",
    "    'loss': 'bce',\n",
    "    'inputs': inputs_config,\n",
    "    'initial_block/inputs': 'raw',\n",
    "    'optimizer': 'Adam',\n",
    "    'head' : dict(layout='Vf', utils=N_NEIGH),\n",
    "    'n_iters': D('size')/B('size'),\n",
    "    'decay': dict(name='exp', gamma=0.99),\n",
    "    'device': 'gpu:0',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(labels, preds):\n",
    "    sigm = torch.nn.Sigmoid()\n",
    "    pred = sigm(torch.Tensor(preds))\n",
    "    preds = np.array(np.array(pred) > .5, dtype=int).ravel()\n",
    "    labels = np.array(labels).ravel()\n",
    "    argsort = np.argsort(preds != labels)[::-1] / 2\n",
    "    return argsort.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_config = {'load' : {'path' : './decrease_prob'},\n",
    "                                    'build': False,\n",
    "                                    'device': 'gpu:0'}\n",
    "\n",
    "batches = np.array([None])\n",
    "train_ppl = prep_ppl + (Pipeline()\n",
    "             .init_model('dynamic', ResNet18, 'model', config)\n",
    "             .update_batch(['raw', 'labels'], from_cont=batches)\n",
    "             .init_variable('loss', init_on_each_run=list)\n",
    "             .init_variable('pred', init_on_each_run=list)\n",
    "             .init_variable('labels', init_on_each_run=list)\n",
    "             .update_variable('labels', B('labels'), mode='w')\n",
    "             .train_model('model', B('raw'), B('labels'),  \n",
    "                          fetches=['loss', 'predictions'], save_to=[V('loss', mode='a'), V('pred', mode='w')])\n",
    "             .HNS('raw', V('labels'), V('pred'), n_worse=50, metric=metric, to=batches)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = (train_ppl << pal_data_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/8000 [00:14<3:02:54,  1.37s/it]"
     ]
    }
   ],
   "source": [
    "z = ppl.run(400, n_epochs=40, shuffle=True, drop_last=True, bar=True, reset=['iter', 'vars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_tr = create_test_ppl(ppl, pal_data_tr, mode='a')\n",
    "ppl_val = create_test_ppl(ppl, pal_data_te, mode='a')\n",
    "ppl_test = create_test_ppl(ppl, wz_data_te, mode='a')\n",
    "\n",
    "ppl_val.run(400, shuffle=True, drop_last=True, n_epochs=1, bar=True)\n",
    "ppl_test.run(400, shuffle=True, drop_last=True, n_epochs=1, bar=True)\n",
    "ppl_tr.run(400, shuffle=True, drop_last=True, n_epochs=1, bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(ppl):\n",
    "    preds, labels = get_results(ppl)\n",
    "    print('Number of inverse traces: {}'.format(sum(labels)))\n",
    "    print('Number of predict inverse traces: {}'.format(sum(preds)))\n",
    "    false_neg = sum(labels[np.where(labels != preds)])\n",
    "    print('Number of missed inverse traces: {}'.format(false_neg))\n",
    "    print('F1 : {}'.format(f1_score(labels, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train traces')\n",
    "calc_metrics(ppl_tr)\n",
    "\n",
    "print('\\n\\nTest traces, same dataset.')\n",
    "calc_metrics(ppl_val)\n",
    "\n",
    "print('\\n\\nTest traces, another dataset.')\n",
    "calc_metrics(ppl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
