{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "### Contents\n",
    "* [Task description](#Task-description)\n",
    "* [The experiment details](#The-experiment-details)\n",
    "* [Results](#Results)\n",
    "\n",
    "### Task description\n",
    "For model performance assessment we want to obtain the distribution of the model quality over 20 independent runs of the training procedure.\n",
    "\n",
    "### The experiment detalis\n",
    "Train and test dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "from seismicpro.batchflow import Dataset, DatasetIndex, Pipeline, B, V, F, C\n",
    "from seismicpro.batchflow.models.tf import UNet\n",
    "from seismicpro.batchflow.research import Research, Option\n",
    "from seismicpro.src import (SeismicBatch, FieldIndex, TraceIndex,\n",
    "                            seismic_plot, spectrum_plot, merge_segy_files,\n",
    "                            show_research, print_results)\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "path_raw = '/notebooks/egor/noise_data/DN02A_LIFT_AMPSCAL.sgy'\n",
    "path_lift = '/notebooks/egor/noise_data/DN02B_SHOTS_LIFT1.sgy'\n",
    "\n",
    "index = (FieldIndex(name='raw', extra_headers=['offset'], path=path_raw)\n",
    "         .merge(FieldIndex(name='lift', path=path_lift)))\n",
    "\n",
    "train_index = index.create_subset(index.indices[:5])\n",
    "train_set = Dataset(TraceIndex(train_index), SeismicBatch)\n",
    "test_set = Dataset(TraceIndex(index.create_subset(index.indices[20:21])), SeismicBatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'initial_block/inputs': 'x',\n",
    "    'inputs': dict(x={'shape': (3000, 1)}, \n",
    "                   y={'name':'targets', 'shape': (3000, 1)}),\n",
    "    'body/filters': C('filters'),\n",
    "    'body/encoder': dict(layout='caca', kernel_size=C('kernel_size'), activation=tf.nn.elu),\n",
    "    'body/downsample': dict(layout='pd', pool_size=2, pool_strides=2, dropout_rate=0.05),\n",
    "    'body/decoder': dict(layout='caca', kernel_size=C('kernel_size'), activation=tf.nn.elu),\n",
    "    'body/upsample': dict(layout='tad', kernel_size=C('kernel_size'), strides=2,\n",
    "                          dropout_rate=0.05, activation=tf.nn.elu),\n",
    "    'loss':'l1',\n",
    "    'optimizer': 'Adam'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train and test pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(batch, **kwagrs):\n",
    "    return {\"feed_dict\": {'x': np.expand_dims(np.vstack(batch.raw), -1),\n",
    "                          'y': np.expand_dims(np.vstack(batch.lift), -1)}}\n",
    "B_SIZE = 128\n",
    "train_pipeline = (Pipeline()\n",
    "                  .load(components=('raw', 'lift'), fmt='segy', tslice=np.arange(3000))\n",
    "                  .init_variable('loss', init_on_each_run=list)\n",
    "                  .init_model('dynamic', UNet, 'unet', model_config)\n",
    "                  .train_model('unet', make_data=make_data,\n",
    "                               fetches='loss', save_to=V('loss'), mode='w')\n",
    "                  .run(B_SIZE, n_epochs=None, drop_last=True, shuffle=True, lazy=True)\n",
    "                 ) << train_set\n",
    "\n",
    "test_pipeline = (Pipeline()\n",
    "                    .import_model('unet', C('import_from'))\n",
    "                    .init_variable('res', init_on_each_run=list())\n",
    "                    .init_variable('raw', init_on_each_run=list())\n",
    "                    .init_variable('lift', init_on_each_run=list())\n",
    "                    .load(components=('raw', 'lift'), tslice=np.arange(3000), fmt='segy')\n",
    "                    .update_variable('raw', B('raw'), mode='a')\n",
    "                    .update_variable('lift', B('lift'), mode='a')\n",
    "                    .predict_model('unet', fetches='predictions', make_data=make_data,\n",
    "                                   save_to=V('res'), mode='a')\n",
    "                    .run(B_SIZE, n_epochs=1, drop_last=True, shuffle=True, lazy=True)\n",
    "                   ) << test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the functions for calculating the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l1(iteration, experiment, pipeline):\n",
    "    \"\"\" Calculate l1 norm.\"\"\"\n",
    "    _ = iteration\n",
    "    pipeline = experiment[pipeline].pipeline\n",
    "    res = np.squeeze(np.vstack(pipeline.get_variable(\"res\")), axis=-1)\n",
    "    lift = np.vstack(np.concatenate(pipeline.get_variable(\"lift\")))\n",
    "    return np.mean(np.abs(res - lift))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a research object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "research = (Research()\n",
    "            .pipeline(train_pipeline, variables='loss', name='train')\n",
    "            .pipeline(test_pipeline, name='test', execute='%5',\n",
    "                      run=True, import_from='train')\n",
    "            .grid({})\n",
    "            .function(get_l1, returns='metrics', name='l1',\n",
    "                      execute='%5', pipeline='test')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 20 independent training and test procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research.run(n_reps=20, n_iters=500, name='reserach_estimation', workers=5,\n",
    "             gpu=[1, 2, 3, 6, 7], progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Histogram and a median value of the test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
